{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105f92bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 17:26:07.059721: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f78856c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리할 텍스트\n",
    "text = \"여의도공원, 샛강공원, 여의도한강시민공원은 모두 여의도에 있다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd33cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('여의도공원, 샛강공원, 여의도한강시민공원은 모두 여의도에 있다.',\n",
       " ['여의도공원', '샛강공원', '여의도한강시민공원은', '모두', '여의도에', '있다'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = text_to_word_sequence(text)\n",
    "text, tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1295dd",
   "metadata": {},
   "source": [
    "### bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6676d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a049f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    '여의도역은 여의도에 있다',\n",
    "    '여의도에 여의도역이 있다',\n",
    "    '서울에 여의도역이 있다',\n",
    "    '어쩌면 서울에 여의도가 있을 수 있다'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a6abc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('여의도역은', 1),\n",
       "             ('여의도에', 2),\n",
       "             ('있다', 4),\n",
       "             ('여의도역이', 2),\n",
       "             ('서울에', 2),\n",
       "             ('어쩌면', 1),\n",
       "             ('여의도가', 1),\n",
       "             ('있을', 1),\n",
       "             ('수', 1)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 수\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(docs)\n",
    "token.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f1625ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장 수\n",
    "token.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d55a66fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'여의도역은': 1,\n",
       "             '있다': 4,\n",
       "             '여의도에': 2,\n",
       "             '여의도역이': 2,\n",
       "             '서울에': 2,\n",
       "             '있을': 1,\n",
       "             '수': 1,\n",
       "             '어쩌면': 1,\n",
       "             '여의도가': 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 단어 별 들어 있는 문장 수\n",
    "token.word_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f049538c",
   "metadata": {},
   "source": [
    "## Token one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af9af63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 토큰 to int value by one-hot\n",
    "\n",
    "# 대상 텍스트\n",
    "text = '오랫동안 꿈꾸는 이는 그 꿈을 닮아간다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57cd696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a91a06b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'오랫동안': 1, '꿈꾸는': 2, '이는': 3, '그': 4, '꿈을': 5, '닮아간다': 6}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word index\n",
    "token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "633a0995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5, 6]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word index로 바꿔주는 함수 사용\n",
    "x = token.texts_to_sequences([text])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88a7e5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# one-hot 결과 만들기\n",
    "# 주의 : index는 0부터 시작하므로, word_size는 +1 해줘야함\n",
    "word_size = len(token.word_index) + 1\n",
    "x = to_categorical(x, num_classes=word_size)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02daf701",
   "metadata": {},
   "source": [
    "### 단어 임베딩word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5aea7301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n입력 16개 단어\\n출력 4개 벡터\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "# Embedding(16, 4)\n",
    "\"\"\"\n",
    "입력 16개 단어\n",
    "출력 4개 벡터\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514c94ee",
   "metadata": {},
   "source": [
    "## 자연어 처리 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e37373db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 영화 리뷰(리뷰, 긍정/부정 여부)\n",
    "reviews = np.array([\n",
    "    ('너무 재미있어요', 1),\n",
    "    ('최고에요', 1),\n",
    "    ('참 잘 만든 영화에요', 1),\n",
    "    ('추천하고 싶은 영화입니다', 1),\n",
    "    ('한 번 더 보고싶네요', 1),\n",
    "    ('별로에요', 0),\n",
    "    ('글쎄요', 0),\n",
    "    ('생각보다 지루하네요', 0),\n",
    "    ('연기가 어색해요', 0),\n",
    "    ('재미없어요', 0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5e6d728b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['너무 재미있어요', '최고에요', '참 잘 만든 영화에요', '추천하고 싶은 영화입니다', '한 번 더 보고싶네요',\n",
       "        '별로에요', '글쎄요', '생각보다 지루하네요', '연기가 어색해요', '재미없어요'], dtype='<U21'),\n",
       " array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰와 긍정/부정 데이터 분리\n",
    "docs = reviews[:, 0]\n",
    "clazz = reviews[:, 1].astype(int)\n",
    "\n",
    "docs, clazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2e7e673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2],\n",
       " [3],\n",
       " [4, 5, 6, 7],\n",
       " [8, 9, 10],\n",
       " [11, 12, 13, 14],\n",
       " [15],\n",
       " [16],\n",
       " [17, 18],\n",
       " [19, 20],\n",
       " [21]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰화\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(docs)\n",
    "x = token.texts_to_sequences(docs)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2652fe1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  1,  2],\n",
       "       [ 0,  0,  0,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 0,  8,  9, 10],\n",
       "       [11, 12, 13, 14],\n",
       "       [ 0,  0,  0, 15],\n",
       "       [ 0,  0,  0, 16],\n",
       "       [ 0,  0, 17, 18],\n",
       "       [ 0,  0, 19, 20],\n",
       "       [ 0,  0,  0, 21]], dtype=int32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 패딩padding\n",
    "\"\"\"\n",
    "토큰화 햇을 때, 각 데이터 길이가 다른 것을 같게 만들어주는 과정\n",
    "\"\"\"\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padded_x = pad_sequences(x, 4)\n",
    "padded_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "666ec7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 8, 4)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임베딩 시, 입력, 출력, 매 시행 입력 수 정해야함\n",
    "# 입력 : 전체 단어 수\n",
    "word_size = len(token.word_index) + 1\n",
    "# 출력 : hyperparamter, hidden layer의 노드와 유사한 역할을 한다\n",
    "output_size = 8\n",
    "# 매 시행 입력 수 : padded word size\n",
    "iter_size = len(padded_x[0])\n",
    "\n",
    "word_size, output_size, iter_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf28ed46",
   "metadata": {},
   "source": [
    "## 자연어 딥러닝 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "80ce5eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8799fc9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 4, 8)              176       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 209\n",
      "Trainable params: 209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Embedding 후 Flatten 해서 1차원 만들고 이를 돌려서 sigmoid로 0 / 1 구분\n",
    "model = Sequential([\n",
    "    Embedding(word_size, output_size, input_length=iter_size),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# 긍 / 부 구분이므로 binary_crossentropy\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "685d5c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1880 - accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1868 - accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1855 - accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1842 - accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1830 - accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1817 - accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1805 - accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1793 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1781 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1769 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1757 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1745 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1733 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1721 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1710 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1698 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1687 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1676 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1664 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1653 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1642 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1631 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1620 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1609 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1599 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1588 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1577 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1567 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1556 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1546 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1536 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1526 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1516 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1505 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1496 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1486 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1476 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1466 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1456 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1447 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1437 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1428 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1418 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1409 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1400 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1391 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1382 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1373 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1364 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1355 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16ed56e50>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_x, clazz, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ea9803c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%ith data predict : %i, real: %i 0 1 1\n",
      "%ith data predict : %i, real: %i 1 1 1\n",
      "%ith data predict : %i, real: %i 2 1 1\n",
      "%ith data predict : %i, real: %i 3 1 1\n",
      "%ith data predict : %i, real: %i 4 1 1\n",
      "%ith data predict : %i, real: %i 5 0 0\n",
      "%ith data predict : %i, real: %i 6 0 0\n",
      "%ith data predict : %i, real: %i 7 0 0\n",
      "%ith data predict : %i, real: %i 8 0 0\n",
      "%ith data predict : %i, real: %i 9 0 0\n"
     ]
    }
   ],
   "source": [
    "# 학습 결과 확인\n",
    "for i in range(len(padded_x)):\n",
    "    [[result]] = model.predict(np.array([padded_x[i]]), verbose=0)\n",
    "    result = 1 if result > 0.5 else 0\n",
    "    \n",
    "    print(f'%ith data predict : %i, real: %i', i, result, clazz[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5963c183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d82b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa951c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be18ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
